%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter2.tex
%% NOVA thesis document file
%%
%% Chapter with the template manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter2.tex}%

\chapter{Data and methods}
\label{cha:data_and_methods}

\section{System Architecture}

The Prompt2Map system is designed to convert natural language queries into interactive web maps by integrating LLMs with geospatial data retrieval and mapping functionalities. The system architecture comprises two main components: the Geospatial Retriever and the Map Generator. This structure is inspired by the Retrieval-Augmented Generation (RAG) architecture, although it differs in that it retrieves geospatial features instead of documents.

The system workflow involves several key steps. When a user inputs a natural language query expressing their mapping needs, the Geospatial Retriever interprets the query and retrieves relevant geospatial data from the data source. Subsequently, the Map Generator transforms the retrieved data and the user's intent into an interactive web map. [Figure @fig:syscomp] shows this process in detail.

%![System components](./figs/syscomp.pdf){#fig:syscomp}

\subsection{Geospatial Retriever}

The Geospatial Retriever is responsible for interpreting the user's natural language query and retrieving the relevant geospatial data from the data source. This process involves several subcomponents, including geospatial data sources, text-to-SQL translation, SQL dialect adaptation, SQL processing and validation, and query execution.

\subsubsection{Geospatial Data Sources}

Geospatial data sources constitute the foundation of any GIS application, encompassing a variety of data formats and storage systems that manage the spatial relationships and attributes of features on the Earth's surface. These data sources can take many forms, such as vector and raster datasets, and are stored in specific formats like Shapefiles, GeoPackage, GeoJSON, GeoParquet, and specialized geospatial databases such as PostGIS and DuckDB. Each data source has unique capabilities, optimized for particular types of spatial data, and supports varying levels of data complexity and query functionality.

Geospatial data sources constitute the foundation of any GIS application, encompassing a variety of data formats and storage systems. Examples of geospatial data sources include Shapefiles, GeoPackage, GeoJSON, GeoParquet, and geospatial databases such as PostGIS and DuckDB. Each data source offers different capabilities and supports various types of spatial data and queries. The type of geospatial data source used in a system like Prompt2Map defines the range and complexity of queries that can be performed.

\subsubsection{Text-to-SQL Translation}

As Prompt2Map adopts a RAG-inspired approach, the first step in addressing user queries is to retrieve data relevant to the request. In this context, the target structured language is SQL, which will be executed against DuckDB to query the geospatial data sources. Traditional text-to-SQL models are trained on generic SQL, focusing on "core SQL" keywords like SELECT, GROUP BY, WHERE, etc. Database-specific syntax, such as spatial extensions, are not inherently recognized by these models.

To address this limitation, instead of fine-tuning the model or extensively modifying the prompts to include spatial extensions, the system translates the user query into regular SQL without explicit mentions of geospatial columns. Subsequently, the query is processed to incorporate geospatial features deterministically. This two-step approach ensures that the text-to-SQL translation remains efficient and cost-effective while enabling the integration of spatial functionalities required for accurate data retrieval.

\subsubsection{SQL Processing and Validation}
The generated SQL query undergoes a processing phase that includes validation and correction. Validation involves checking the query for syntactic correctness, security (e.g., preventing SQL injection), and adherence to read-only constraints to protect data integrity. This ensures that the query is safe to execute and will not compromise the underlying database.

Beyond mere validation, the system actively repairs queries by identifying and rectifying potential issues that could lead to incorrect or empty results. For example, if the WHERE clause contains incorrect literals or references nonexistent fields, the system attempts to correct these errors by aligning them with the actual data schema and available metadata. This dual approach of validation and correction enhances the reliability and accuracy of the data retrieval process, ensuring that the resulting datasets are both relevant and correctly structured for subsequent mapping tasks.

After validation, the SQL query is converted to a geospatial DuckDB SQL query by injecting the necessary spatial features. This deterministic modification ensures that the query leverages DuckDB's spatial functions appropriately, enabling accurate and efficient data retrieval based on the user's natural language input.

\subsubsection{Query Execution}
The validated and corrected SQL query is executed against the geospatial data source. The choice of DuckDB as the database engine allows for efficient handling of both single-table and multi-table environments. DuckDB's support for various geospatial data formats and its in-process architecture facilitate seamless data access and manipulation, ensuring that the system can handle a wide range of geospatial queries with high performance.

\subsection{Map Generator}
The Map Generator component transforms the retrieved geospatial data and the user's intent into an interactive web map. This process involves function calling with LLMs, mapping function selection, parameter specification, and map rendering.

\subsubsection{Function Calling with LLMs}
The system utilizes the function-calling feature provided by major LLM API providers, including OpenAI, Claude, and Groq. Function calling allows the LLM to invoke predefined functions with specific parameters based on the user's query and the data characteristics. In this context, the functions correspond to mapping operations, such as generating a choropleth map, a heatmap, or a proportional symbol map. Each function has defined parameters, such as data layers, visual variables, styling options, and interactivity settings.

The LLM analyzes the metadata of the retrieved data, including geometry types, attributes, and spatial relationships. Based on this analysis and the user's intent, the LLM selects the most appropriate mapping function. For example, if the data consists of polygons with quantitative attributes and the user requests to visualize rates or densities, the LLM may select a choropleth mapping function. For point data representing events or occurrences, a heatmap function might be appropriate. Once the mapping function is selected, the LLM specifies the parameters required for the function. These include data layers to be visualized, visual variables to represent attributes through color, size, shape, or texture, styling options like color schemes and classification methods, and interactivity settings such as tooltips, pop-ups, and legends.

The mapping function is executed to render the interactive web map. The system employs web mapping libraries such as Leaflet or Plotly, which support interactive features and responsive design. The final map allows users to interact with the data, providing functionalities like zooming, panning, clicking on features to display attribute information, and toggling layers on and off.

\section{Implementation}
%The logical design described in the previous section was implemented as an open-source Python package, available via Python Package Index (PyPI)[^1] and Github[^2]. [Figure @fig:codeimp] shows a Unified Modeling Language (UML) diagram with the project classes and their dependencies.

%[^1]: \url{https://pypi.org/project/prompt2map/}
%[^2]: \url{https://github.com/josemcorderoc/prompt2map}

%![UML class diagram of Prompt2Map implementation in Python](./figs/code_implementation.pdf){#fig:codeimp}

The implementation of Prompt2Map follows a modular architecture, organized into three primary modules: interfaces, providers, and application. This structure adheres to the principles of Clean Architecture, ensuring that the core application logic remains decoupled from external dependencies and infrastructure concerns. Each module serves a distinct purpose within the system, facilitating scalability, maintainability, and ease of integration with various components. In this design paradigm, the application layer is decoupled from the infrastructure layer (providers) by relying on abstract interfaces rather than concrete implementations. 

This approach ensures that the core business logic remains unaffected by changes in external systems or technologies. Specifically, Prompt2Map defines interfaces such as GeoDatabase, Embedding, and LLM within the interfaces module, which outline the essential functionalities required by the application. The providers module contains concrete implementations like GeoDuckDB and OpenAIProvider, which fulfill these interfaces. This modular structure offers significant advantages, including ease of maintenance, scalability, and flexibility. For instance, integrating support for a different geospatial database, such as PostgreSQL with PostGIS, would simply involve creating a new class that implements the GeoDatabase interface without altering the core application logic. This decoupling facilitates adaptability to evolving technological landscapes and simplifies the extension of system capabilities.

Python serves as the primary programming language for implementing Prompt2Map, chosen for its versatility, extensive library support, and strong presence in both the AI and geospatial communities. Python’s rich ecosystem includes powerful libraries like GeoPandas, which extends Pandas to enable spatial operations on geospatial data, making it an ideal tool for managing and analyzing geographic information within the system.

\subsection{Application}
The application component constitutes the core functionality of the prompt2map package, orchestrating the end-to-end process of converting natural language queries into interactive web maps. This component is responsible for managing the workflow from query interpretation to data retrieval and finally to map generation. By leveraging the abstract interfaces defined within the interfaces module and utilizing the concrete implementations provided by the providers, the application layer ensures seamless interaction between different system modules. This modular approach not only enhances the system's scalability but also facilitates easier maintenance and future enhancements.

Within the application component, key classes such as `SQLGeoRetriever`, `LLMPrompt2SQL`, `LLMMapGenerator`, and `Prompt2Map` play pivotal roles. `SQLGeoRetriever` handles the translation of natural language queries into SQL statements and manages the retrieval of geospatial data from the database. `LLMPrompt2SQL` utilizes the capabilities of LLMs to accurately convert user prompts into executable SQL queries, ensuring that the data retrieval process aligns with the user's intent. `LLMMapGenerator` is tasked with transforming the retrieved geospatial data into visually coherent and interactive maps, selecting appropriate visualization techniques based on the nature of the data and the user's requirements. Finally, the `Prompt2Map` class serves as the primary interface for users, integrating the functionalities of the retriever and generator to deliver a cohesive mapping experience. This structured separation of responsibilities within the application component ensures that each aspect of the system operates efficiently and cohesively.

\subsection{Interfaces}
The interfaces component serves as the foundational layer of the prompt2map package, defining the abstract contracts that dictate how different modules interact with one another. By establishing clear and standardized interfaces, the system ensures that each component adheres to a consistent set of functionalities, promoting interoperability and flexibility. This abstraction is crucial for maintaining a decoupled architecture, allowing individual modules to be developed, tested, and maintained independently without impacting the overall system integrity.

Key interfaces within this component include `Embedding`, `LLM`, `GeoDatabase`, `GeoRetriever`, `Prompt2SQL`, and `MapGenerator`. The `Embedding` interface outlines the methods required for generating numerical representations of textual data, which are essential for tasks like similarity matching and query understanding. The `LLM` interface defines the interaction methods with Large Language Models, facilitating tasks such as prompt-based query generation and response handling. `GeoDatabase` encapsulates the functionalities needed to interact with geospatial databases, including schema retrieval and geospatial data querying. `GeoRetriever` specifies the methods for fetching geospatial data based on user queries, ensuring that the application can retrieve relevant and accurate datasets. `Prompt2SQL` bridges the gap between natural language inputs and structured SQL queries, enabling the seamless translation of user intents into executable database commands. Lastly, the `MapGenerator` interface outlines the methods for creating interactive maps from geospatial data, ensuring that visualizations are generated consistently and effectively. By defining these interfaces, the system promotes a high level of abstraction and modularity, allowing for easy integration of new functionalities and technologies as the system evolves.

\subsection{Providers}
The providers component encapsulates the concrete implementations of the abstract interfaces defined within the interfaces module. This layer is responsible for managing interactions with external services and tools, effectively bridging the gap between the system's core functionalities and the underlying technologies that enable them. By centralizing these implementations within the providers, the system achieves a high degree of flexibility and adaptability, allowing for seamless integration of new services or replacement of existing ones without disrupting the core application logic.

Within the providers module, classes such as `GeoDuckDB` and `OpenAIProvider` play critical roles. `GeoDuckDB` implements the `GeoDatabase` interface, managing all interactions with DuckDB, the chosen geospatial database engine. This includes handling data storage, executing spatial queries, and managing database connections. DuckDB's in-process architecture and robust support for various geospatial data formats make it an ideal choice for efficient data retrieval and management within Prompt2Map. On the other hand, `OpenAIProvider` implements both the `LLM` and `Embedding` interfaces, facilitating interactions with the OpenAI API. This provider manages the communication with Large Language Models, enabling the system to leverage advanced natural language processing capabilities for tasks such as text-to-SQL translation and function calling. By abstracting these external dependencies into dedicated provider classes, the system ensures that changes or updates to external services can be accommodated with minimal impact on the overall architecture. Additionally, this separation of concerns enhances the maintainability and scalability of the system, allowing developers to focus on core functionalities without being bogged down by the complexities of external service integrations.

\subsection{External Dependencies}
The prompt2map package leverages several external dependencies to achieve its functionality, each chosen for its robustness, performance, and compatibility with the system's requirements.

\subsubsection{OpenAI API}
The OpenAI API is integrated into Prompt2Map to leverage the advanced natural language processing capabilities of LLMs like GPT-4. This API facilitates the system’s ability to interpret and translate natural language queries into executable SQL statements through the text-to-SQL functionality. By utilizing the OpenAI API, Prompt2Map can effectively handle complex and nuanced user inputs, ensuring accurate data retrieval and meaningful map generation. The API provides access to powerful language models that excel in understanding context, disambiguating meanings, and generating coherent and contextually relevant responses. Additionally, the OpenAI API supports function calling, allowing Prompt2Map to invoke predefined mapping functions with specific parameters based on user queries. This integration enhances the system’s ability to maintain consistency and standardization in map generation, as the predefined functions ensure that all maps adhere to established cartographic principles and visualization standards. Moreover, the use of the OpenAI API abstracts the complexities of managing and deploying LLMs, enabling Prompt2Map to focus on delivering a seamless and user-friendly GIS experience without the overhead of maintaining sophisticated NLP infrastructure.


\subsubsection{DuckDB}
DuckDB is employed as the primary geospatial database engine within Prompt2Map, selected for its high performance, in-process architecture \cite{raasveldt_duckdb_2019},  and comprehensive support for geospatial data types and functions. Unlike traditional SQL databases that require separate server infrastructure, DuckDB operates entirely within the application’s process, eliminating the need for additional setup and reducing latency in data retrieval. Its geospatial extension provides robust capabilities for handling spatial queries, including spatial joins, proximity searches, and geographic aggregations, which are essential for generating accurate and informative maps. DuckDB's ability to efficiently manage large datasets and perform complex queries makes it an ideal choice for Prompt2Map, ensuring swift data processing and reliable performance. Furthermore, DuckDB'’s compatibility with various geospatial data formats, such as GeoJSON, Shapefiles, and GeoParquet, enhances the system's flexibility and ease of data integration, allowing Prompt2Map to seamlessly incorporate diverse geospatial datasets without compromising on performance or functionality.


\section{Data}
The Prompt2Map system is designed to work with various structured spatial data sources. For this thesis, two datasets are used to evaluate the system: the Portuguese 2021 Census Data and the Chilean Elections Database. Detailed descriptions of the variables used in these datasets are provided in the appendix.

This dataset includes demographic and socioeconomic information collected during the 2021 census in Portugal. It is structured in a single-table format, suitable for testing basic SQL queries and simple map visualizations. The data attributes encompass population counts (total population, age groups), socioeconomic indicators (employment rates, education levels, household income), and geographic units (administrative boundaries at different levels, such as municipalities and regions). The dataset provides a comprehensive overview of the demographic and socioeconomic landscape of Portugal, making it ideal for evaluating the system's ability to handle standard geospatial queries and produce accurate visualizations with minimal complexity. The data is obtained from the Portuguese National Statistics Institute (INE) \cite{INE2021Census}.

\section{Evaluation}

% Paragraph 1: The challenges of measuring the performance of Prompt2Map

Evaluating the performance of Prompt2Map poses several challenges due to the system's unique characteristics, including the integration of natural language processing, geospatial data retrieval, and map generation functionalities. Traditional evaluation metrics used in NLP, such as BLEU scores or F1 scores, may not fully capture the system's effectiveness in converting natural language queries into interactive web maps. Therefore, a comprehensive evaluation strategy is required to assess the system's performance across different dimensions, including accuracy, efficiency, usability, and scalability.

% Paragraph 2: Say that for the scope of this thesis, we focus on the text-to-SQL evaluation (this is, the retriever), as the mapping evaluation is more subjective. And also the map is generated basically by the webmap libraries

Nevertheless, for the scope of this thesis, the evaluation focuses on the text-to-SQL translation component of Prompt2Map, which corresponds to the Geospatial Retriever in the system architecture. This evaluation aims to assess the system's ability to accurately interpret natural language queries, generate SQL statements that retrieve relevant geospatial data, and execute these queries against the geospatial database. The evaluation of the Map Generator component, which involves the creation of interactive web maps based on the retrieved geospatial data, is more subjective and user-dependent, making it challenging to define objective metrics. Therefore, the focus of this evaluation is on the Geospatial Retriever, which forms the foundation of the system's functionality.


\subsection{Metrics}

Two main metrics are used to evaluate the Prompt2Map performancce: Soft F1-score and Consistency Score.
% Paragraph 1: Describe the metrics used to evaluate accuracy


The primary metric used to evaluate accuracy is Soft F1-score. Regular F1-score is common in classification tasks, where the goal is to balance precision and recall.

\subsubsection{The problem with text-to-SQL metrics}

Can a question be represented as a SQL query? This is the main question that text-to-SQL systems aim to answer. However, evaluating the performance of these systems is challenging due to the inherent ambiguity and complexity of natural language queries. Even for human annotators, determining the correct SQL query for a given question can be a non-trivial task, as it requires an understanding of the underlying database schema, the semantics of the question, and the intended query result. Therefore, developing robust evaluation metrics that can accurately assess the performance of text-to-SQL systems is crucial for advancing the field and enabling fair comparisons between different approaches.

There are multiple benchmarks for text-to-SQL evaluation, such as Spider \cite{yu_spider_2018}, BIRD \cite{li_can_2023} and WikiSQL \cite{zhongSeq2SQL2017}. These benchmarks provide standardized datasets with natural language questions paired with their corresponding SQL queries, allowing researchers to evaluate the performance of their systems on common tasks. The two main evaluation metrics for the text-to-SQL task are Exact Matching (EM) and Execution Accuracy (EX). EM measures the syntax-level equivalence between the generated SQL query and the ground truth query, while EX evaluates the execution results of the generated query.

However, those metrics have limitations that can lead to biased results and inaccurate performance assessments (Lopez). While EM evaluates the syntax-level equivalence of queries, it often leads to high false negative rates, as the same logical intent can be represented through various query structures and alises. On the other hand, EX focuses on the execution results of the generated queries, providing a more robust evaluation metric. However, EX is not without its limitations, as it can produce false positives when incorrect queries yield correct results, and false negatives when extra fields are included in the output.

The hardness of EM and EX is that both require exact matches between the generated SQL query and the ground truth. This is a very strict requirement, as even small variations in the generated query can lead to a mismatch. To address this issue, the Soft F1-score was introduced as a more lenient evaluation metric that considers the data similarity between the generated and ground truth queries. 

The original F1-score is a metric commonly used in classification tasks to balance the model's ability to correctly identify positive samples (precision) and to capture all positive samples (recall).

\begin{equation}
    F1 = 2 \times \frac{precision \times recall}{precision + recall}
\end{equation}

\subsubsection{Consistency}

To assess the consistency of the Prompt2Map outputs across multiple runs, we introduced a metric termed Consistency Entropy. This metric is derived from the normalized entropy of the model's output distribution across repeated trials for the same prompt. In this context, lower entropy signifies higher consistency, as the model consistently generates similar outputs for identical inputs. Normalized entropy was chosen to ensure comparability across varying levels of output complexity, where more complex maps naturally involve higher diversity. This metric provides insight into the stability and reliability of the system, which are critical for practical applications.

a measure of uncertainty, or of "poorness of a guess," which will be high when the number of alternative possibilities is nigh, and low when some of the possibilities are much more likely than others

In addition to Consistency Entropy, the frequency of the mode is used. This metric provides a simple yet effective measure of the most common output generated by the system across multiple runs. A high mode frequency indicates that the system consistently produces a specific output, which can be beneficial for tasks requiring deterministic results. By combining Consistency Entropy and mode frequency, the evaluation framework captures both the diversity and stability of the system's outputs, offering a comprehensive assessment of its performance.

\begin{equation}
    H(X) = - \sum_{i=1}^{n} p(x_i) \log_2 p(x_i)
\end{equation}

\begin{equation}
    H_{rel}(X) = \frac{H(X)}{\log_2 n} 
\end{equation}


Mode frequency: frequency of the most frequent item
\begin{equation}
    \text{Mode Frequency (X)} = \frac{\text{Number of occurrences of the mode}}{\text{Total number of runs}} = \frac{\max_{x \in X} \text{count}(x)}{|X|}
\end{equation}

